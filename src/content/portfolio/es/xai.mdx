---
title: "XAI"
description: "Un módulo conceptual para facilitar la planificación y comunicación de esfuerzos de inteligencia artificial (IA) explicable/interpretable (XAI)"
locale: "es"
pubDate: "May 17 2024"
updateDate: "Aug 09 2024"
heroImage: "@assets/banner-xai.webp"
stack: ["AI", "Etica"]
tags: ["digitales"]

---

Un módulo conceptual para facilitar la planificación y comunicación de esfuerzos de inteligencia artificial (IA) explicable/interpretable (XAI).

Este proyecto se encuentra desarrollo. Un resume del progreso está disponible [aquí](#).

## Resumen
Actualmente, hay mucho interés en hacer que la IA sea más explicable (causas y resultados) y/o interpretable (lógica y proceso).

Existen técnicas para lograr un grado de explicabilidad y/o interpretabilidad de la IA, como los árboles de decisión, Grad-CAM (Gradient-weighted Class Activation Mapping), SHAP (Shapley Additive exPlanations) y LIME (Local Interpretable Model-agnostic Explanations), entre otras.

Lo que no está tan claro es el nivel al que estas técnicas dan explicabilidad/interpretabilidad (explican/interpretan mucho, poco, o nada?), ni los plazos involucrados (se puede pedir explicabilidad o interpretabilidad en X días/meses/años?).

Pensando en este tema, me puse a desarrollar un modelo conceptual que ayude a planificar y comunicar más fácilmente los esfuerzos de explicabilidad/interpretabilidad de IA.

Para ser claro, mi objetivo en este proyecto no es hacer la IA más explicable o interpretable. Para eso están las técnicas que mencioné y otras. El objetivo es crear un recurso que ayude a los desarrolladores e implementadores IA a planear y/o comunicar sus esfuerzos XAI.

## Estado
Este proyecto se encuentra actualmente en desarrollo y tiene prioridad baja, principalmente porque es algo que quiero pensar con el detenimiento que merece.